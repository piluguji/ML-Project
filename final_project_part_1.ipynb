{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_MF3_VWHLjz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(dataset):\n",
        "  X = dataset.iloc[:, :-1]  # Features\n",
        "  y = dataset.iloc[:, -1]   # Classification\n",
        "\n",
        "  # Separate numerical and categorical features\n",
        "  categorical_features = X.select_dtypes(include=['object']).columns\n",
        "  numerical_features = X.drop(categorical_features, axis=1)\n",
        "  categorical_features = X[categorical_features]\n",
        "\n",
        "  # 80-20 train-test split of data\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "\n",
        "  # Encode categorical features using LabelEncoder\n",
        "  label_encoder = LabelEncoder()\n",
        "  for column in categorical_features.columns:\n",
        "      X_train[column] = label_encoder.fit_transform(X_train[column])\n",
        "      X_test[column] = label_encoder.transform(X_test[column])\n",
        "\n",
        "\n",
        "  # Normalize data using StandardScaler for continuous features\n",
        "  scaler = StandardScaler()\n",
        "  X_train = scaler.fit_transform(X_train)\n",
        "  X_test = scaler.transform(X_test)\n",
        "\n",
        "  return X_train, X_test, y_train, y_test\n"
      ],
      "metadata": {
        "id": "-_BG9YbrHkgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross Validation + Metrics"
      ],
      "metadata": {
        "id": "BVK9bAy6XQVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_classifier(clf, X_train, X_test, y_train, y_test, cv=10):\n",
        "    # 10-fold cross-validation\n",
        "    cv_results = cross_validate(clf, X_train, y_train, cv=10, scoring=['accuracy', 'precision', 'recall', 'f1', 'roc_auc'], return_estimator=True)\n",
        "\n",
        "    # metrics on the training set\n",
        "    accuracy = cv_results['test_accuracy'].mean()\n",
        "    precision = cv_results['test_precision'].mean()\n",
        "    recall = cv_results['test_recall'].mean()\n",
        "    f1 = cv_results['test_f1'].mean()\n",
        "    auc = cv_results['test_roc_auc'].mean()\n",
        "    print(f\"Training Accuracy: {accuracy}\")\n",
        "    print(f\"Training Precision: {precision}\")\n",
        "    print(f\"Training Recall: {recall}\")\n",
        "    print(f\"Training F1 Score: {f1}\")\n",
        "    print(f\"Training AUC: {auc}\")\n",
        "\n",
        "    # identify model with the best accuracy on the training set\n",
        "    best_model_index = max(range(10), key=lambda i: cv_results['test_accuracy'][i])\n",
        "    best_model = cv_results['estimator'][best_model_index]\n",
        "\n",
        "    # predict on the test set using the best model\n",
        "    y_pred_test = best_model.predict(X_test)\n",
        "\n",
        "    # metrics on the test set\n",
        "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
        "    print(f\"Test Accuracy: {accuracy_test}\")"
      ],
      "metadata": {
        "id": "bjhbRGghpdSO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "AngnLj-_HOoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_regression(X_train, y_train, reg_technique, reg_solver):\n",
        "  clf = LogisticRegression(penalty=reg_technique, solver=reg_solver)\n",
        "  clf.fit(X_train, y_train)\n",
        "  return clf"
      ],
      "metadata": {
        "id": "lAGhsczfMAJ0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K Nearest Number"
      ],
      "metadata": {
        "id": "SVNhzhoahl0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def k_nearest_neighbor(X_train, y_train, k_value):\n",
        "  clf = KNeighborsClassifier(n_neighbors=k_value)\n",
        "  clf.fit(X_train, y_train)\n",
        "  return clf"
      ],
      "metadata": {
        "id": "7aEG06ythk9b"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM"
      ],
      "metadata": {
        "id": "Q2g9Gp1CTwMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def support_vector_machine(X_train, y_train, kernel_func):\n",
        "  clf = SVC(kernel=kernel_func)\n",
        "  clf.fit(X_train, y_train)\n",
        "  return clf"
      ],
      "metadata": {
        "id": "IfSs0jAbTqEd"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree"
      ],
      "metadata": {
        "id": "VT474OkRTl0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decision_tree(X_train, y_train):\n",
        "  clf = DecisionTreeClassifier()\n",
        "  clf.fit(X_train, y_train)\n",
        "  return clf"
      ],
      "metadata": {
        "id": "nsrK6RfLTnjP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "jUlHRbwcV_LQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_forest(X_train, y_train):\n",
        "  clf = RandomForestClassifier()\n",
        "  clf.fit(X_train, y_train)\n",
        "  return clf"
      ],
      "metadata": {
        "id": "uWV_uA-2V-rw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boosting"
      ],
      "metadata": {
        "id": "Xkawl7l3WCMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def boosting(X_train, y_train):\n",
        "  # AdaBoost with Decision Tree as base estimator\n",
        "  base_estimator = DecisionTreeClassifier(max_depth=1)\n",
        "  clf = AdaBoostClassifier(estimator=base_estimator)\n",
        "  clf.fit(X_train, y_train)\n",
        "  return clf"
      ],
      "metadata": {
        "id": "6OcPqMbEWB7E"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training + Testing Model Metrics on Datasets"
      ],
      "metadata": {
        "id": "a3S0PEgtXyZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1 = pd.read_csv('project3_dataset1.txt', delimiter='\\t')\n",
        "dataset2 = pd.read_csv('project3_dataset2.txt', delimiter='\\t')\n",
        "X_train1, X_test1, y_train1, y_test1 = preprocess_data(dataset1)\n",
        "X_train2, X_test2, y_train2, y_test2 = preprocess_data(dataset2)\n",
        "\n",
        "print(\"Logistic Regression\")\n",
        "print(\"Dataset 1\")\n",
        "clf_lr1 = logistic_regression(X_train1, y_train1, 'l2', 'liblinear')\n",
        "evaluate_classifier(clf_lr1, X_train1, X_test1, y_train1, y_test1)\n",
        "print(\"\\nDataset 2\")\n",
        "clf_lr2 = logistic_regression(X_train2, y_train2, 'l1', 'liblinear')\n",
        "evaluate_classifier(clf_lr2, X_train2, X_test2, y_train2, y_test2)\n",
        "\n",
        "print(\"\\nK Nearest Neighbor\")\n",
        "print(\"Dataset 1\")\n",
        "clf_knn1 = k_nearest_neighbor(X_train1, y_train1, 5)\n",
        "evaluate_classifier(clf_knn1, X_train1, X_test1, y_train1, y_test1)\n",
        "print(\"\\nDataset 2\")\n",
        "clf_knn2 = k_nearest_neighbor(X_train2, y_train2, 26)\n",
        "evaluate_classifier(clf_knn2, X_train2, X_test2, y_train2, y_test2)\n",
        "\n",
        "print(\"\\nSupport Vector Machine\")\n",
        "print(\"Dataset 1\")\n",
        "clf_svm1 = support_vector_machine(X_train1, y_train1, 'linear')\n",
        "evaluate_classifier(clf_svm1, X_train1, X_test1, y_train1, y_test1)\n",
        "print(\"\\nDataset 2\")\n",
        "clf_svm2 = support_vector_machine(X_train2, y_train2, 'rbf')\n",
        "evaluate_classifier(clf_svm2, X_train2, X_test2, y_train2, y_test2)\n",
        "\n",
        "print(\"\\nDecision Tree\")\n",
        "print(\"Dataset 1\")\n",
        "clf_dt1 = decision_tree(X_train1, y_train1)\n",
        "evaluate_classifier(clf_dt1, X_train1, X_test1, y_train1, y_test1)\n",
        "print(\"\\nDataset 2\")\n",
        "clf_dt2 = decision_tree(X_train2, y_train2)\n",
        "evaluate_classifier(clf_dt2, X_train2, X_test2, y_train2, y_test2)\n",
        "\n",
        "print(\"\\nRandom Forest\")\n",
        "print(\"Dataset 1\")\n",
        "clf_rf1 = random_forest(X_train1, y_train1)\n",
        "evaluate_classifier(clf_rf1, X_train1, X_test1, y_train1, y_test1)\n",
        "print(\"\\nDataset 2\")\n",
        "clf_rf2 = random_forest(X_train2, y_train2)\n",
        "evaluate_classifier(clf_rf2, X_train2, X_test2, y_train2, y_test2)\n",
        "\n",
        "print(\"\\nBoosting\")\n",
        "print(\"Dataset 1\")\n",
        "clf_boosting1 = boosting(X_train1, y_train1)\n",
        "evaluate_classifier(clf_boosting1, X_train1, X_test1, y_train1, y_test1)\n",
        "print(\"\\nDataset 2\")\n",
        "clf_boosting2 = boosting(X_train2, y_train2)\n",
        "evaluate_classifier(clf_boosting2, X_train2, X_test2, y_train2, y_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCjTZZsyXwos",
        "outputId": "f3f09389-a7a8-4002-bdaa-09988188dfdf"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression\n",
            "Dataset 1\n",
            "Training Accuracy: 0.9758454106280194\n",
            "Training Precision: 0.9791812865497075\n",
            "Training Recall: 0.9588235294117646\n",
            "Training F1 Score: 0.9673966935151146\n",
            "Training AUC: 0.9965155027528253\n",
            "Test Accuracy: 0.9824561403508771\n",
            "\n",
            "Dataset 2\n",
            "Training Accuracy: 0.7361861861861863\n",
            "Training Precision: 0.6574206349206351\n",
            "Training Recall: 0.4685897435897436\n",
            "Training F1 Score: 0.5358642819169136\n",
            "Training AUC: 0.7652521367521368\n",
            "Test Accuracy: 0.7204301075268817\n",
            "\n",
            "K Nearest Neighbor\n",
            "Dataset 1\n",
            "Training Accuracy: 0.9756521739130435\n",
            "Training Precision: 0.99375\n",
            "Training Recall: 0.9411764705882353\n",
            "Training F1 Score: 0.9660984848484848\n",
            "Training AUC: 0.9917379020573748\n",
            "Test Accuracy: 0.9385964912280702\n",
            "\n",
            "Dataset 2\n",
            "Training Accuracy: 0.7171171171171171\n",
            "Training Precision: 0.602857142857143\n",
            "Training Recall: 0.2891025641025641\n",
            "Training F1 Score: 0.3791205397629546\n",
            "Training AUC: 0.7441207264957266\n",
            "Test Accuracy: 0.6881720430107527\n",
            "\n",
            "Support Vector Machine\n",
            "Dataset 1\n",
            "Training Accuracy: 0.9735748792270531\n",
            "Training Precision: 0.978328173374613\n",
            "Training Recall: 0.9529411764705882\n",
            "Training F1 Score: 0.9640790857702622\n",
            "Training AUC: 0.994617502173283\n",
            "Test Accuracy: 0.9649122807017544\n",
            "\n",
            "Dataset 2\n",
            "Training Accuracy: 0.7364114114114114\n",
            "Training Precision: 0.6688888888888889\n",
            "Training Recall: 0.39679487179487183\n",
            "Training F1 Score: 0.48105487649605294\n",
            "Training AUC: 0.7164594017094018\n",
            "Test Accuracy: 0.7204301075268817\n",
            "\n",
            "Decision Tree\n",
            "Dataset 1\n",
            "Training Accuracy: 0.9471497584541062\n",
            "Training Precision: 0.9313994545186496\n",
            "Training Recall: 0.9297385620915032\n",
            "Training F1 Score: 0.9288055859273279\n",
            "Training AUC: 0.9436870150358996\n",
            "Test Accuracy: 0.8947368421052632\n",
            "\n",
            "Dataset 2\n",
            "Training Accuracy: 0.64984984984985\n",
            "Training Precision: 0.4624969474969475\n",
            "Training Recall: 0.4435897435897436\n",
            "Training F1 Score: 0.44172290506938505\n",
            "Training AUC: 0.5975448717948718\n",
            "Test Accuracy: 0.6129032258064516\n",
            "\n",
            "Random Forest\n",
            "Dataset 1\n",
            "Training Accuracy: 0.9603381642512077\n",
            "Training Precision: 0.9601827485380117\n",
            "Training Recall: 0.9356209150326797\n",
            "Training F1 Score: 0.9460145388371194\n",
            "Training AUC: 0.9917938439743714\n",
            "Test Accuracy: 0.9473684210526315\n",
            "\n",
            "Dataset 2\n",
            "Training Accuracy: 0.6986486486486486\n",
            "Training Precision: 0.5599855699855699\n",
            "Training Recall: 0.38653846153846155\n",
            "Training F1 Score: 0.4449957990962837\n",
            "Training AUC: 0.7381068376068376\n",
            "Test Accuracy: 0.6881720430107527\n",
            "\n",
            "Boosting\n",
            "Dataset 1\n",
            "Training Accuracy: 0.9713526570048309\n",
            "Training Precision: 0.982638888888889\n",
            "Training Recall: 0.9415032679738562\n",
            "Training F1 Score: 0.9603496369222176\n",
            "Training AUC: 0.9925283331723496\n",
            "Test Accuracy: 0.9473684210526315\n",
            "\n",
            "Dataset 2\n",
            "Training Accuracy: 0.6630630630630632\n",
            "Training Precision: 0.5105555555555557\n",
            "Training Recall: 0.43589743589743596\n",
            "Training F1 Score: 0.4572991822991823\n",
            "Training AUC: 0.6758408119658119\n",
            "Test Accuracy: 0.6236559139784946\n"
          ]
        }
      ]
    }
  ]
}