{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "V_MF3_VWHLjz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(dataset):\n",
        "  X = dataset.iloc[:, :-1]  # Features\n",
        "  y = dataset.iloc[:, -1]   # Classification\n",
        "\n",
        "  # Separate numerical and categorical features\n",
        "  categorical_features = X.select_dtypes(include=['object']).columns\n",
        "  numerical_features = X.drop(categorical_features, axis=1)\n",
        "  categorical_features = X[categorical_features]\n",
        "\n",
        "  # 80-20 train-test split of data\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "\n",
        "  # Encode categorical features using LabelEncoder\n",
        "  label_encoder = LabelEncoder()\n",
        "  for column in categorical_features.columns:\n",
        "      X_train[column] = label_encoder.fit_transform(X_train[column])\n",
        "      X_test[column] = label_encoder.transform(X_test[column])\n",
        "\n",
        "\n",
        "  # Normalize data using StandardScaler for continuous features\n",
        "  scaler = StandardScaler()\n",
        "  X_train = scaler.fit_transform(X_train)\n",
        "  X_test = scaler.transform(X_test)\n",
        "\n",
        "  return X_train, X_test, y_train, y_test\n"
      ],
      "metadata": {
        "id": "-_BG9YbrHkgr"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross Validation + Metrics"
      ],
      "metadata": {
        "id": "BVK9bAy6XQVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_classifier(clf, X_train, X_test, y_train, y_test, cv=10):\n",
        "    # 10-fold cross-validation\n",
        "    cv_results = cross_validate(clf, X_train, y_train, cv=10, scoring=['accuracy', 'precision', 'recall', 'f1', 'roc_auc'], return_estimator=True)\n",
        "\n",
        "    # metrics on the training set\n",
        "    accuracy = cv_results['test_accuracy'].mean()\n",
        "    precision = cv_results['test_precision'].mean()\n",
        "    recall = cv_results['test_recall'].mean()\n",
        "    f1 = cv_results['test_f1'].mean()\n",
        "    auc = cv_results['test_roc_auc'].mean()\n",
        "    print(f\"Training Accuracy: {accuracy}\")\n",
        "    print(f\"Training Precision: {precision}\")\n",
        "    print(f\"Training Recall: {recall}\")\n",
        "    print(f\"Training F1 Score: {f1}\")\n",
        "    print(f\"Training AUC: {auc}\")\n",
        "\n",
        "    # identify model with the best accuracy on the training set\n",
        "    best_model_index = max(range(10), key=lambda i: cv_results['test_accuracy'][i])\n",
        "    best_model = cv_results['estimator'][best_model_index]\n",
        "\n",
        "    # predict on the test set using the best model\n",
        "    y_pred_test = best_model.predict(X_test)\n",
        "\n",
        "    # metrics on the test set\n",
        "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
        "    print(f\"Test Accuracy: {accuracy_test}\")"
      ],
      "metadata": {
        "id": "bjhbRGghpdSO"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "AngnLj-_HOoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_regression(X_train, y_train):\n",
        "  clf = LogisticRegression()\n",
        "  clf.fit(X_train, y_train)\n",
        "  return clf\n",
        "print(\"Logistic Regression base\")\n",
        "print(\"Dataset 1\")\n",
        "clf_lr1 = logistic_regression(X_train1, y_train1)\n",
        "evaluate_classifier(clf_lr1, X_train1, X_test1, y_train1, y_test1)\n",
        "print(\"\\nDataset 2\")\n",
        "clf_lr2 = logistic_regression(X_train2, y_train2)\n",
        "evaluate_classifier(clf_lr2, X_train2, X_test2, y_train2, y_test2)"
      ],
      "metadata": {
        "id": "lAGhsczfMAJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55a2f2bb-1c27-4a94-b47e-cbf0233b2b87"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression base\n",
            "Dataset 1\n",
            "Training Accuracy: 0.9758454106280194\n",
            "Training Precision: 0.9791812865497075\n",
            "Training Recall: 0.9588235294117646\n",
            "Training F1 Score: 0.9673966935151146\n",
            "Training AUC: 0.9965155027528253\n",
            "Test Accuracy: 0.9824561403508771\n",
            "\n",
            "Dataset 2\n",
            "Training Accuracy: 0.7363363363363364\n",
            "Training Precision: 0.6655555555555556\n",
            "Training Recall: 0.4769230769230769\n",
            "Training F1 Score: 0.5414556489262371\n",
            "Training AUC: 0.7662649572649572\n",
            "Test Accuracy: 0.7096774193548387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K Nearest Number"
      ],
      "metadata": {
        "id": "SVNhzhoahl0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def k_nearest_neighbor(X_train, y_train):\n",
        "  clf = KNeighborsClassifier()\n",
        "  clf.fit(X_train, y_train)\n",
        "  return clf"
      ],
      "metadata": {
        "id": "7aEG06ythk9b"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree"
      ],
      "metadata": {
        "id": "VT474OkRTl0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decision_tree(X_train, y_train):\n",
        "  clf = DecisionTreeClassifier()\n",
        "  clf.fit(X_train, y_train)\n",
        "  return clf"
      ],
      "metadata": {
        "id": "nsrK6RfLTnjP"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM"
      ],
      "metadata": {
        "id": "Q2g9Gp1CTwMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def support_vector_machine(X_train, y_train):\n",
        "  clf = SVC()\n",
        "  clf.fit(X_train, y_train)\n",
        "  return clf\n",
        "\n",
        "dataset1 = pd.read_csv('project3_dataset1.txt', delimiter='\\t')\n",
        "dataset2 = pd.read_csv('project3_dataset2.txt', delimiter='\\t')\n",
        "X_train1, X_test1, y_train1, y_test1 = preprocess_data(dataset1)\n",
        "X_train2, X_test2, y_train2, y_test2 = preprocess_data(dataset2)\n",
        "\n",
        "print(\"Linear kernal \")\n",
        "clf = SVC(kernel='linear')\n",
        "clf.fit(X_train2, y_train2)\n",
        "evaluate_classifier(clf, X_train2, X_test2, y_train2, y_test2)\n",
        "print(\"rbf kernal \")\n",
        "clf = SVC(kernel='rbf', C=2)\n",
        "clf.fit(X_train2, y_train2)\n",
        "evaluate_classifier(clf, X_train2, X_test2, y_train2, y_test2)\n",
        "print(\"poly kernal \")\n",
        "clf = SVC(kernel='poly')\n",
        "clf.fit(X_train2, y_train2)\n",
        "evaluate_classifier(clf, X_train2, X_test2, y_train2, y_test2)\n",
        "print(\"sigmoid kernal \")\n",
        "clf = SVC(kernel='sigmoid')\n",
        "clf.fit(X_train2, y_train2)\n",
        "evaluate_classifier(clf, X_train2, X_test2, y_train2, y_test2)"
      ],
      "metadata": {
        "id": "IfSs0jAbTqEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d24698ca-52c3-44dd-8731-07034f34b8d0"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear kernal \n",
            "Training Accuracy: 0.7228978978978979\n",
            "Training Precision: 0.6669871794871793\n",
            "Training Recall: 0.42756410256410254\n",
            "Training F1 Score: 0.49540142554384037\n",
            "Training AUC: 0.7583322649572649\n",
            "Test Accuracy: 0.6989247311827957\n",
            "rbf kernal \n",
            "Training Accuracy: 0.741891891891892\n",
            "Training Precision: 0.6851010101010101\n",
            "Training Recall: 0.4301282051282051\n",
            "Training F1 Score: 0.5125338145798504\n",
            "Training AUC: 0.7114871794871794\n",
            "Test Accuracy: 0.7204301075268817\n",
            "poly kernal \n",
            "Training Accuracy: 0.7203453453453454\n",
            "Training Precision: 0.6502380952380953\n",
            "Training Recall: 0.2814102564102564\n",
            "Training F1 Score: 0.3788731633004079\n",
            "Training AUC: 0.735758547008547\n",
            "Test Accuracy: 0.7096774193548387\n",
            "sigmoid kernal \n",
            "Training Accuracy: 0.6955705705705706\n",
            "Training Precision: 0.5772258297258297\n",
            "Training Recall: 0.40961538461538466\n",
            "Training F1 Score: 0.46695907448767854\n",
            "Training AUC: 0.7086858974358974\n",
            "Test Accuracy: 0.6989247311827957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "jUlHRbwcV_LQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_forest(X_train, y_train, max_depth=None):\n",
        "  clf = RandomForestClassifier(max_depth=max_depth)\n",
        "  clf.fit(X_train, y_train)\n",
        "  return clf"
      ],
      "metadata": {
        "id": "uWV_uA-2V-rw"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boosting"
      ],
      "metadata": {
        "id": "Xkawl7l3WCMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def boosting(X_train, y_train):\n",
        "  # AdaBoost with Decision Tree as base estimator\n",
        "  base_estimator = DecisionTreeClassifier(max_depth=1)\n",
        "  clf = AdaBoostClassifier(estimator=base_estimator)\n",
        "  clf.fit(X_train, y_train)\n",
        "  return clf"
      ],
      "metadata": {
        "id": "6OcPqMbEWB7E"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training + Testing Model Metrics on Datasets"
      ],
      "metadata": {
        "id": "a3S0PEgtXyZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1 = pd.read_csv('project3_dataset1.txt', delimiter='\\t')\n",
        "dataset2 = pd.read_csv('project3_dataset2.txt', delimiter='\\t')\n",
        "X_train1, X_test1, y_train1, y_test1 = preprocess_data(dataset1)\n",
        "X_train2, X_test2, y_train2, y_test2 = preprocess_data(dataset2)\n",
        "\n",
        "print(\"Logistic Regression\")\n",
        "print(\"Dataset 1\")\n",
        "clf_lr1 = logistic_regression(X_train1, y_train1)\n",
        "evaluate_classifier(clf_lr1, X_train1, X_test1, y_train1, y_test1)\n",
        "print(\"\\nDataset 2\")\n",
        "clf_lr2 = logistic_regression(X_train2, y_train2)\n",
        "evaluate_classifier(clf_lr2, X_train2, X_test2, y_train2, y_test2)\n",
        "\n",
        "print(\"\\nK Nearest Neighbor\")\n",
        "print(\"Dataset 1\")\n",
        "clf_knn1 = k_nearest_neighbor(X_train1, y_train1)\n",
        "evaluate_classifier(clf_knn1, X_train1, X_test1, y_train1, y_test1)\n",
        "print(\"\\nDataset 2\")\n",
        "clf_knn2 = k_nearest_neighbor(X_train2, y_train2)\n",
        "evaluate_classifier(clf_knn2, X_train2, X_test2, y_train2, y_test2)\n",
        "\n",
        "print(\"\\nDecision Tree\")\n",
        "print(\"Dataset 1\")\n",
        "clf_dt1 = decision_tree(X_train1, y_train1)\n",
        "evaluate_classifier(clf_dt1, X_train1, X_test1, y_train1, y_test1)\n",
        "print(\"\\nDataset 2\")\n",
        "clf_dt2 = decision_tree(X_train2, y_train2)\n",
        "evaluate_classifier(clf_dt2, X_train2, X_test2, y_train2, y_test2)\n",
        "\n",
        "print(\"\\nSupport Vector Machine\")\n",
        "print(\"Dataset 1\")\n",
        "clf_svm1 = support_vector_machine(X_train1, y_train1)\n",
        "evaluate_classifier(clf_svm1, X_train1, X_test1, y_train1, y_test1)\n",
        "print(\"\\nDataset 2\")\n",
        "clf_svm2 = support_vector_machine(X_train2, y_train2)\n",
        "evaluate_classifier(clf_svm2, X_train2, X_test2, y_train2, y_test2)\n",
        "\n",
        "print(\"\\nRandom Forest\")\n",
        "print(\"Dataset 1\")\n",
        "clf_rf1 = random_forest(X_train1, y_train1)\n",
        "evaluate_classifier(clf_rf1, X_train1, X_test1, y_train1, y_test1)\n",
        "print(\"\\nDataset 2\")\n",
        "clf_rf2 = random_forest(X_train2, y_train2)\n",
        "evaluate_classifier(clf_rf2, X_train2, X_test2, y_train2, y_test2)\n",
        "\n",
        "print(\"\\nBoosting\")\n",
        "print(\"Dataset 1\")\n",
        "clf_boosting1 = boosting(X_train1, y_train1)\n",
        "evaluate_classifier(clf_boosting1, X_train1, X_test1, y_train1, y_test1)\n",
        "print(\"\\nDataset 2\")\n",
        "clf_boosting2 = boosting(X_train2, y_train2)\n",
        "evaluate_classifier(clf_boosting2, X_train2, X_test2, y_train2, y_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCjTZZsyXwos",
        "outputId": "feb0b984-04cb-4cf8-a2bd-52eb7d44c89b"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression\n",
            "Dataset 1\n",
            "Training Accuracy: 0.9758454106280194\n",
            "Training Precision: 0.9791812865497075\n",
            "Training Recall: 0.9588235294117646\n",
            "Training F1 Score: 0.9673966935151146\n",
            "Training AUC: 0.9965155027528253\n",
            "Test Accuracy: 0.9824561403508771\n",
            "\n",
            "Dataset 2\n",
            "Training Accuracy: 0.7363363363363364\n",
            "Training Precision: 0.6655555555555556\n",
            "Training Recall: 0.4769230769230769\n",
            "Training F1 Score: 0.5414556489262371\n",
            "Training AUC: 0.7662649572649572\n",
            "Test Accuracy: 0.7096774193548387\n",
            "\n",
            "K Nearest Neighbor\n",
            "Dataset 1\n",
            "Training Accuracy: 0.9756521739130435\n",
            "Training Precision: 0.99375\n",
            "Training Recall: 0.9411764705882353\n",
            "Training F1 Score: 0.9660984848484848\n",
            "Training AUC: 0.9917379020573748\n",
            "Test Accuracy: 0.9385964912280702\n",
            "\n",
            "Dataset 2\n",
            "Training Accuracy: 0.673948948948949\n",
            "Training Precision: 0.5178571428571428\n",
            "Training Recall: 0.3467948717948718\n",
            "Training F1 Score: 0.40250263339508185\n",
            "Training AUC: 0.6597911324786325\n",
            "Test Accuracy: 0.5913978494623656\n",
            "\n",
            "Decision Tree\n",
            "Dataset 1\n",
            "Training Accuracy: 0.9515942028985507\n",
            "Training Precision: 0.9503887168902649\n",
            "Training Recall: 0.9238562091503267\n",
            "Training F1 Score: 0.9348885968443046\n",
            "Training AUC: 0.946102981422454\n",
            "Test Accuracy: 0.8859649122807017\n",
            "\n",
            "Dataset 2\n",
            "Training Accuracy: 0.6551801801801802\n",
            "Training Precision: 0.46515151515151515\n",
            "Training Recall: 0.4352564102564102\n",
            "Training F1 Score: 0.44392537414276545\n",
            "Training AUC: 0.5995448717948718\n",
            "Test Accuracy: 0.6344086021505376\n",
            "\n",
            "Support Vector Machine\n",
            "Dataset 1\n",
            "Training Accuracy: 0.9779710144927536\n",
            "Training Precision: 0.9780357757137942\n",
            "Training Recall: 0.9647058823529411\n",
            "Training F1 Score: 0.9703247957659723\n",
            "Training AUC: 0.9954984867510224\n",
            "Test Accuracy: 0.956140350877193\n",
            "\n",
            "Dataset 2\n",
            "Training Accuracy: 0.7364114114114114\n",
            "Training Precision: 0.6688888888888889\n",
            "Training Recall: 0.39679487179487183\n",
            "Training F1 Score: 0.48105487649605294\n",
            "Training AUC: 0.7164594017094018\n",
            "Test Accuracy: 0.7204301075268817\n",
            "\n",
            "Random Forest\n",
            "Dataset 1\n",
            "Training Accuracy: 0.9602898550724637\n",
            "Training Precision: 0.9595635534915721\n",
            "Training Recall: 0.9356209150326797\n",
            "Training F1 Score: 0.9458651916289487\n",
            "Training AUC: 0.9928849125857241\n",
            "Test Accuracy: 0.9473684210526315\n",
            "\n",
            "Dataset 2\n",
            "Training Accuracy: 0.7067567567567569\n",
            "Training Precision: 0.573946608946609\n",
            "Training Recall: 0.40320512820512827\n",
            "Training F1 Score: 0.4617634239050311\n",
            "Training AUC: 0.7288514957264957\n",
            "Test Accuracy: 0.6236559139784946\n",
            "\n",
            "Boosting\n",
            "Dataset 1\n",
            "Training Accuracy: 0.9713526570048309\n",
            "Training Precision: 0.982638888888889\n",
            "Training Recall: 0.9415032679738562\n",
            "Training F1 Score: 0.9603496369222176\n",
            "Training AUC: 0.9925283331723496\n",
            "Test Accuracy: 0.9473684210526315\n",
            "\n",
            "Dataset 2\n",
            "Training Accuracy: 0.6630630630630632\n",
            "Training Precision: 0.5105555555555557\n",
            "Training Recall: 0.43589743589743596\n",
            "Training F1 Score: 0.4572991822991823\n",
            "Training AUC: 0.6758408119658119\n",
            "Test Accuracy: 0.6236559139784946\n"
          ]
        }
      ]
    }
  ]
}